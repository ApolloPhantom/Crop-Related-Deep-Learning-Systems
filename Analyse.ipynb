{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 345407 entries, 0 to 345406\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   State             345407 non-null  object \n",
      " 1   District          345407 non-null  object \n",
      " 2   Crop              345375 non-null  object \n",
      " 3   Year              345407 non-null  object \n",
      " 4   Season            345406 non-null  object \n",
      " 5   Area              345374 non-null  float64\n",
      " 6   Area Units        345407 non-null  object \n",
      " 7   Production        340414 non-null  float64\n",
      " 8   Production Units  345407 non-null  object \n",
      " 9   Yield             345374 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 26.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"Data/India Agriculture Crop Production.csv\")\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in State is 36\n",
      "Unique values in District is 729\n",
      "Unique values in Crop is 56\n",
      "Unique values in Year is 24\n",
      "Unique values in Season is 6\n",
      "Unique values in Area is 48006\n",
      "Unique values in Area Units is 1\n",
      "Unique values in Production is 69078\n",
      "Unique values in Production Units is 3\n",
      "Unique values in Yield is 197154\n"
     ]
    }
   ],
   "source": [
    "for i in df1.columns:\n",
    "    print(f\"Unique values in {i} is {df1[i].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2001-02' '2002-03' '2003-04' '2004-05' '2005-06' '2006-07' '2007-08'\n",
      " '2008-09' '2009-10' '2010-11' '2011-12' '2012-13' '2013-14' '2014-15'\n",
      " '2015-16' '2016-17' '2017-18' '2018-19' '2019-20' '2020-21' '2000-01'\n",
      " '1997-98' '1998-99' '1999-00']\n"
     ]
    }
   ],
   "source": [
    "Year = df1[\"Year\"].unique()\n",
    "print(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50,10))\n",
    "# sns.barplot(data=df1,x=\"Year\",y=\"Production\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50,10))\n",
    "# sns.barplot(data=df1,x=\"State\",y=\"Production\",hue=\"Production Units\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tonnes' 'Nuts' 'Bales']\n"
     ]
    }
   ],
   "source": [
    "Units = df1[\"Production Units\"].unique()\n",
    "print(Units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx = df1[df1[\"Production Units\"]==\"Tonnes\"]\n",
    "dfy = df1[df1[\"Production Units\"]==\"Nuts\"]\n",
    "dfz = df1[df1[\"Production Units\"]==\"Bales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 331686 entries, 0 to 345406\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   State             331686 non-null  object \n",
      " 1   District          331686 non-null  object \n",
      " 2   Crop              331654 non-null  object \n",
      " 3   Year              331686 non-null  object \n",
      " 4   Season            331685 non-null  object \n",
      " 5   Area              331653 non-null  float64\n",
      " 6   Area Units        331686 non-null  object \n",
      " 7   Production        326999 non-null  float64\n",
      " 8   Production Units  331686 non-null  object \n",
      " 9   Yield             331653 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 27.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2927 entries, 20 to 343483\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             2927 non-null   object \n",
      " 1   District          2927 non-null   object \n",
      " 2   Crop              2927 non-null   object \n",
      " 3   Year              2927 non-null   object \n",
      " 4   Season            2927 non-null   object \n",
      " 5   Area              2927 non-null   float64\n",
      " 6   Area Units        2927 non-null   object \n",
      " 7   Production        2891 non-null   float64\n",
      " 8   Production Units  2927 non-null   object \n",
      " 9   Yield             2927 non-null   float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 251.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10794 entries, 546 to 344185\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   State             10794 non-null  object \n",
      " 1   District          10794 non-null  object \n",
      " 2   Crop              10794 non-null  object \n",
      " 3   Year              10794 non-null  object \n",
      " 4   Season            10794 non-null  object \n",
      " 5   Area              10794 non-null  float64\n",
      " 6   Area Units        10794 non-null  object \n",
      " 7   Production        10524 non-null  float64\n",
      " 8   Production Units  10794 non-null  object \n",
      " 9   Yield             10794 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 927.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dfx.info()\n",
    "dfy.info()\n",
    "dfz.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State                  0\n",
      "District               0\n",
      "Crop                  32\n",
      "Year                   0\n",
      "Season                 1\n",
      "Area                  33\n",
      "Area Units             0\n",
      "Production          4687\n",
      "Production Units       0\n",
      "Yield                 33\n",
      "dtype: int64 \n",
      "\n",
      "State                0\n",
      "District             0\n",
      "Crop                 0\n",
      "Year                 0\n",
      "Season               0\n",
      "Area                 0\n",
      "Area Units           0\n",
      "Production          36\n",
      "Production Units     0\n",
      "Yield                0\n",
      "dtype: int64 \n",
      "\n",
      "State                 0\n",
      "District              0\n",
      "Crop                  0\n",
      "Year                  0\n",
      "Season                0\n",
      "Area                  0\n",
      "Area Units            0\n",
      "Production          270\n",
      "Production Units      0\n",
      "Yield                 0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Null Value Analysis\n",
    "\n",
    "print(dfx.isnull().sum(),\"\\n\")\n",
    "print(dfy.isnull().sum(),\"\\n\")\n",
    "print(dfz.isnull().sum(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arecanut' 'Banana' 'Black pepper' 'Cashewnut' 'Dry chillies' 'Ginger'\n",
      " 'Other Kharif pulses' 'other oilseeds' 'Rice' 'Sugarcane' 'Sweet potato'\n",
      " 'Arhar/Tur' 'Bajra' 'Castor seed' 'Coriander' 'Gram' 'Groundnut'\n",
      " 'Horse-gram' 'Jowar' 'Linseed' 'Maize' 'Moong(Green Gram)' 'Niger seed'\n",
      " 'Onion' 'Other Rabi pulses' 'Potato' 'Ragi' 'Rapeseed &Mustard'\n",
      " 'Safflower' 'Sesamum' 'Small millets' 'Soyabean' 'Sunflower' 'Tapioca'\n",
      " 'Tobacco' 'Turmeric' 'Urad' 'Wheat' 'Oilseeds total' 'Masoor'\n",
      " 'Peas & beans (Pulses)' 'Barley' 'Garlic' 'Khesari' 'Sannhamp'\n",
      " 'Guar seed' 'Moth' 'Cardamom' 'Other Cereals' 'Cowpea(Lobia)'\n",
      " 'Dry Ginger' 'Other Summer Pulses' nan]\n",
      "52\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(dfx[\"Crop\"].unique())\n",
    "print(dfx[\"Crop\"].nunique())\n",
    "print(dfx[\"Crop\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Area</th>\n",
       "      <th>Area Units</th>\n",
       "      <th>Production</th>\n",
       "      <th>Production Units</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345375</th>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>DADRA AND NAGAR HAVELI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345376</th>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>DADRA AND NAGAR HAVELI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-19</td>\n",
       "      <td>Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345377</th>\n",
       "      <td>Dadra and Nagar Haveli</td>\n",
       "      <td>DADRA AND NAGAR HAVELI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345378</th>\n",
       "      <td>Daman and Diu</td>\n",
       "      <td>DIU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345379</th>\n",
       "      <td>Daman and Diu</td>\n",
       "      <td>DAMAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345380</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>BISHNUPUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345381</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>CHANDEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345382</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>CHURACHANDPUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345383</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>IMPHAL EAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345384</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>IMPHAL WEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345385</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>SENAPATI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345386</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>TAMENGLONG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345387</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>THOUBAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345388</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>UKHRUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345389</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>BISHNUPUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345390</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>CHANDEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345391</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>CHURACHANDPUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345392</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>IMPHAL EAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345393</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>IMPHAL WEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345394</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>SENAPATI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345395</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>TAMENGLONG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345396</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>THOUBAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345397</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>UKHRUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345398</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>BISHNUPUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345399</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>CHANDEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345400</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>CHURACHANDPUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345401</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>IMPHAL EAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345402</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>IMPHAL WEST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345403</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>SENAPATI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345404</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>TAMENGLONG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345405</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>THOUBAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345406</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>UKHRUL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hectare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tonnes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State                District Crop     Year  \\\n",
       "345375  Dadra and Nagar Haveli  DADRA AND NAGAR HAVELI  NaN  2019-20   \n",
       "345376  Dadra and Nagar Haveli  DADRA AND NAGAR HAVELI  NaN  2018-19   \n",
       "345377  Dadra and Nagar Haveli  DADRA AND NAGAR HAVELI  NaN  2019-20   \n",
       "345378           Daman and Diu                     DIU  NaN  2019-20   \n",
       "345379           Daman and Diu                   DAMAN  NaN  2019-20   \n",
       "345380                 Manipur               BISHNUPUR  NaN  2019-20   \n",
       "345381                 Manipur                 CHANDEL  NaN  2019-20   \n",
       "345382                 Manipur           CHURACHANDPUR  NaN  2019-20   \n",
       "345383                 Manipur             IMPHAL EAST  NaN  2019-20   \n",
       "345384                 Manipur             IMPHAL WEST  NaN  2019-20   \n",
       "345385                 Manipur                SENAPATI  NaN  2019-20   \n",
       "345386                 Manipur              TAMENGLONG  NaN  2019-20   \n",
       "345387                 Manipur                 THOUBAL  NaN  2019-20   \n",
       "345388                 Manipur                  UKHRUL  NaN  2019-20   \n",
       "345389                 Manipur               BISHNUPUR  NaN  2019-20   \n",
       "345390                 Manipur                 CHANDEL  NaN  2019-20   \n",
       "345391                 Manipur           CHURACHANDPUR  NaN  2019-20   \n",
       "345392                 Manipur             IMPHAL EAST  NaN  2019-20   \n",
       "345393                 Manipur             IMPHAL WEST  NaN  2019-20   \n",
       "345394                 Manipur                SENAPATI  NaN  2019-20   \n",
       "345395                 Manipur              TAMENGLONG  NaN  2019-20   \n",
       "345396                 Manipur                 THOUBAL  NaN  2019-20   \n",
       "345397                 Manipur                  UKHRUL  NaN  2019-20   \n",
       "345398                 Manipur               BISHNUPUR  NaN  2019-20   \n",
       "345399                 Manipur                 CHANDEL  NaN  2019-20   \n",
       "345400                 Manipur           CHURACHANDPUR  NaN  2019-20   \n",
       "345401                 Manipur             IMPHAL EAST  NaN  2019-20   \n",
       "345402                 Manipur             IMPHAL WEST  NaN  2019-20   \n",
       "345403                 Manipur                SENAPATI  NaN  2019-20   \n",
       "345404                 Manipur              TAMENGLONG  NaN  2019-20   \n",
       "345405                 Manipur                 THOUBAL  NaN  2019-20   \n",
       "345406                 Manipur                  UKHRUL  NaN  2019-20   \n",
       "\n",
       "            Season  Area Area Units  Production Production Units  Yield  \n",
       "345375      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345376      Winter   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345377        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345378      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345379      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345380      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345381      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345382      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345383      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345384      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345385      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345386      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345387      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345388      Kharif   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345389  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345390  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345391  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345392  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345393  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345394  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345395  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345396  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345397  Whole Year   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345398        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345399        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345400        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345401        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345402        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345403        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345404        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345405        Rabi   NaN    Hectare         NaN           Tonnes    NaN  \n",
       "345406        Rabi   NaN    Hectare         NaN           Tonnes    NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx[dfx[\"Crop\"].isnull()].head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State                  0\n",
      "District               0\n",
      "Crop                  32\n",
      "Year                   0\n",
      "Season                 1\n",
      "Area                  33\n",
      "Area Units             0\n",
      "Production          4687\n",
      "Production Units       0\n",
      "Yield                 33\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 331686 entries, 0 to 345406\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   State             331686 non-null  object \n",
      " 1   District          331686 non-null  object \n",
      " 2   Crop              331654 non-null  object \n",
      " 3   Year              331686 non-null  object \n",
      " 4   Season            331685 non-null  object \n",
      " 5   Area              331653 non-null  float64\n",
      " 6   Area Units        331686 non-null  object \n",
      " 7   Production        326999 non-null  float64\n",
      " 8   Production Units  331686 non-null  object \n",
      " 9   Yield             331653 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 27.8+ MB\n",
      "None\n",
      "State               0\n",
      "District            0\n",
      "Crop                0\n",
      "Year                0\n",
      "Season              0\n",
      "Area                0\n",
      "Area Units          0\n",
      "Production          0\n",
      "Production Units    0\n",
      "Yield               0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   State             326999 non-null  object \n",
      " 1   District          326999 non-null  object \n",
      " 2   Crop              326999 non-null  object \n",
      " 3   Year              326999 non-null  object \n",
      " 4   Season            326999 non-null  object \n",
      " 5   Area              326999 non-null  float64\n",
      " 6   Area Units        326999 non-null  object \n",
      " 7   Production        326999 non-null  float64\n",
      " 8   Production Units  326999 non-null  object \n",
      " 9   Yield             326999 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 27.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dfx.isnull().sum())\n",
    "print(dfx.info())\n",
    "dfx = dfx.dropna(subset=['Crop'])\n",
    "dfx = dfx.dropna(subset=['Season'])\n",
    "dfx = dfx.dropna(subset=['Area'])\n",
    "dfx = dfx.dropna(subset=['Production'])\n",
    "print(dfx.isnull().sum())\n",
    "print(dfx.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Steps of 23 has 420 unique values\n",
      "Time Steps of 7 has 8 unique values\n",
      "Time Steps of 4 has 25 unique values\n",
      "Time Steps of 12 has 11 unique values\n",
      "Time Steps of 24 has 10 unique values\n",
      "Time Steps of 10 has 2 unique values\n",
      "Time Steps of 17 has 17 unique values\n",
      "Time Steps of 22 has 96 unique values\n",
      "Time Steps of 16 has 4 unique values\n",
      "Time Steps of 18 has 4 unique values\n",
      "Time Steps of 6 has 9 unique values\n",
      "Time Steps of 11 has 3 unique values\n",
      "Time Steps of 3 has 3 unique values\n",
      "Time Steps of 21 has 29 unique values\n",
      "Time Steps of 1 has 36 unique values\n",
      "Time Steps of 15 has 7 unique values\n",
      "Time Steps of 9 has 11 unique values\n",
      "Time Steps of 13 has 11 unique values\n",
      "Time Steps of 20 has 3 unique values\n",
      "Time Steps of 8 has 8 unique values\n",
      "Time Steps of 2 has 5 unique values\n",
      "Time Steps of 5 has 2 unique values\n",
      "Time Steps of 19 has 1 unique values\n",
      "Time Steps of 14 has 3 unique values\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "years_per_district = dfx.groupby('District')['Year'].unique()\n",
    "maxx = defaultdict(int)\n",
    "for i in years_per_district:\n",
    "    maxx[len(i)] += 1\n",
    "\n",
    "for i in maxx.keys():\n",
    "    print(f\"Time Steps of {i} has {maxx[i]} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State               0\n",
      "District            0\n",
      "Crop                0\n",
      "Year                0\n",
      "Season              0\n",
      "Area                0\n",
      "Area Units          0\n",
      "Production          0\n",
      "Production Units    0\n",
      "Yield               0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   State             326999 non-null  object \n",
      " 1   District          326999 non-null  object \n",
      " 2   Crop              326999 non-null  object \n",
      " 3   Year              326999 non-null  object \n",
      " 4   Season            326999 non-null  object \n",
      " 5   Area              326999 non-null  float64\n",
      " 6   Area Units        326999 non-null  object \n",
      " 7   Production        326999 non-null  float64\n",
      " 8   Production Units  326999 non-null  object \n",
      " 9   Yield             326999 non-null  float64\n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 27.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dfx.isnull().sum())\n",
    "print(dfx.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   Year        326999 non-null  datetime64[ns]\n",
      " 1   Area        326999 non-null  float64       \n",
      " 2   Production  326999 non-null  float64       \n",
      " 3   Yield       326999 non-null  float64       \n",
      " 4   Unique_ID   326999 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(1)\n",
      "memory usage: 15.0+ MB\n"
     ]
    }
   ],
   "source": [
    "dfx1 = dfx.drop(columns=['Production Units', 'Area Units'])\n",
    "dfx1['State'] = dfx1['State'].str.lower().str.strip()\n",
    "dfx1['District'] = dfx1['District'].str.lower().str.strip()\n",
    "dfx1['Crop'] = dfx1['Crop'].str.lower().str.strip()\n",
    "dfx1['Season'] = dfx1['Season'].str.lower().str.strip()\n",
    "dfx1['Unique_ID'] = dfx1['State'] + '-'+ dfx1['District'] + '-' + dfx1['Crop'] + '-' + dfx1['Season']\n",
    "dfx1 = dfx1.drop(columns=['State','District','Crop','Season'])\n",
    "dfx1['Year'] = dfx1['Year'].str[:4]\n",
    "dfx1['Year'] = pd.to_datetime(dfx1['Year'], format='%Y')\n",
    "dfx1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Steps of 2 has 3043 unique values\n",
      "Time Steps of 1 has 6296 unique values\n",
      "Time Steps of 10 has 767 unique values\n",
      "Time Steps of 4 has 1920 unique values\n",
      "Time Steps of 16 has 830 unique values\n",
      "Time Steps of 5 has 1423 unique values\n",
      "Time Steps of 7 has 1480 unique values\n",
      "Time Steps of 6 has 1183 unique values\n",
      "Time Steps of 3 has 1991 unique values\n",
      "Time Steps of 12 has 902 unique values\n",
      "Time Steps of 8 has 880 unique values\n",
      "Time Steps of 15 has 848 unique values\n",
      "Time Steps of 9 has 793 unique values\n",
      "Time Steps of 11 has 882 unique values\n",
      "Time Steps of 14 has 725 unique values\n",
      "Time Steps of 13 has 841 unique values\n",
      "Time Steps of 22 has 1668 unique values\n",
      "Time Steps of 23 has 2404 unique values\n",
      "Time Steps of 19 has 900 unique values\n",
      "Time Steps of 18 has 936 unique values\n",
      "Time Steps of 17 has 679 unique values\n",
      "Time Steps of 21 has 1116 unique values\n",
      "Time Steps of 20 has 1301 unique values\n"
     ]
    }
   ],
   "source": [
    "years_per_id = dfx1.groupby('Unique_ID')['Year'].unique()\n",
    "maxx = defaultdict(int)\n",
    "for i in years_per_id:\n",
    "    maxx[len(i)] += 1\n",
    "\n",
    "for i in maxx.keys():\n",
    "    print(f\"Time Steps of {i} has {maxx[i]} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Year has 24 unique values\n",
      "Column Area has 46121 unique values\n",
      "Column Production has 64373 unique values\n",
      "Column Yield has 188361 unique values\n",
      "Column Unique_ID has 33808 unique values\n"
     ]
    }
   ],
   "source": [
    "for i in dfx1.columns:\n",
    "    print(f\"Column {i} has {dfx1[i].nunique()} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   Year        326999 non-null  datetime64[ns]\n",
      " 1   Area        326999 non-null  float64       \n",
      " 2   Production  326999 non-null  float64       \n",
      " 3   Yield       326999 non-null  float64       \n",
      " 4   Unique_ID   326999 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1)\n",
      "memory usage: 13.7 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "dfx1['Unique_ID'] = label_encoder.fit_transform(dfx1['Unique_ID'])\n",
    "dfx1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   Year               326999 non-null  datetime64[ns]\n",
      " 1   Area               326999 non-null  float64       \n",
      " 2   Production         326999 non-null  float64       \n",
      " 3   Yield              326999 non-null  float64       \n",
      " 4   Unique_ID          326999 non-null  int32         \n",
      " 5   Production_lag_1   293191 non-null  float64       \n",
      " 6   Production_lag_2   265679 non-null  float64       \n",
      " 7   Production_lag_3   241210 non-null  float64       \n",
      " 8   Production_lag_4   218732 non-null  float64       \n",
      " 9   Production_lag_5   198174 non-null  float64       \n",
      " 10  Production_lag_6   179039 non-null  float64       \n",
      " 11  Production_lag_7   161087 non-null  float64       \n",
      " 12  Production_lag_8   144615 non-null  float64       \n",
      " 13  Production_lag_9   129023 non-null  float64       \n",
      " 14  Production_lag_10  114224 non-null  float64       \n",
      " 15  Production_lag_11  100192 non-null  float64       \n",
      " 16  Production_lag_12  87042 non-null   float64       \n",
      " 17  Production_lag_13  74794 non-null   float64       \n",
      " 18  Production_lag_14  63387 non-null   float64       \n",
      " 19  Production_lag_15  52705 non-null   float64       \n",
      " 20  Production_lag_16  42871 non-null   float64       \n",
      " 21  Production_lag_17  33867 non-null   float64       \n",
      " 22  Production_lag_18  25542 non-null   float64       \n",
      " 23  Production_lag_19  18153 non-null   float64       \n",
      " 24  Production_lag_20  11664 non-null   float64       \n",
      " 25  Production_lag_21  6476 non-null    float64       \n",
      " 26  Production_lag_22  2404 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(25), int32(1)\n",
      "memory usage: 68.6 MB\n"
     ]
    }
   ],
   "source": [
    "grouped = dfx1.groupby('Unique_ID')\n",
    "num_lags = 22\n",
    "for i in range(1, num_lags + 1):\n",
    "    dfx1[f'Production_lag_{i}'] = grouped['Production'].shift(i)\n",
    "\n",
    "dfx1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                      0\n",
      "Area                      0\n",
      "Production                0\n",
      "Yield                     0\n",
      "Unique_ID                 0\n",
      "Production_lag_1      33808\n",
      "Production_lag_2      61320\n",
      "Production_lag_3      85789\n",
      "Production_lag_4     108267\n",
      "Production_lag_5     128825\n",
      "Production_lag_6     147960\n",
      "Production_lag_7     165912\n",
      "Production_lag_8     182384\n",
      "Production_lag_9     197976\n",
      "Production_lag_10    212775\n",
      "Production_lag_11    226807\n",
      "Production_lag_12    239957\n",
      "Production_lag_13    252205\n",
      "Production_lag_14    263612\n",
      "Production_lag_15    274294\n",
      "Production_lag_16    284128\n",
      "Production_lag_17    293132\n",
      "Production_lag_18    301457\n",
      "Production_lag_19    308846\n",
      "Production_lag_20    315335\n",
      "Production_lag_21    320523\n",
      "Production_lag_22    324595\n",
      "dtype: int64\n",
      "Year                      0\n",
      "Area                      0\n",
      "Production                0\n",
      "Yield                     0\n",
      "Unique_ID                 0\n",
      "Production_lag_1          2\n",
      "Production_lag_2         16\n",
      "Production_lag_3      40159\n",
      "Production_lag_4      40163\n",
      "Production_lag_5      40180\n",
      "Production_lag_6      80479\n",
      "Production_lag_7      80487\n",
      "Production_lag_8      80489\n",
      "Production_lag_9     123056\n",
      "Production_lag_10    123058\n",
      "Production_lag_11    123060\n",
      "Production_lag_12    166777\n",
      "Production_lag_13    166778\n",
      "Production_lag_14    166779\n",
      "Production_lag_15    212391\n",
      "Production_lag_16    212392\n",
      "Production_lag_17    212393\n",
      "Production_lag_18    263413\n",
      "Production_lag_19    280797\n",
      "Production_lag_20    281973\n",
      "Production_lag_21    281974\n",
      "Production_lag_22    282070\n",
      "dtype: int64\n",
      "Year                 0\n",
      "Area                 0\n",
      "Production           0\n",
      "Yield                0\n",
      "Unique_ID            0\n",
      "Production_lag_1     0\n",
      "Production_lag_2     0\n",
      "Production_lag_3     0\n",
      "Production_lag_4     0\n",
      "Production_lag_5     0\n",
      "Production_lag_6     0\n",
      "Production_lag_7     0\n",
      "Production_lag_8     0\n",
      "Production_lag_9     0\n",
      "Production_lag_10    0\n",
      "Production_lag_11    0\n",
      "Production_lag_12    0\n",
      "Production_lag_13    0\n",
      "Production_lag_14    0\n",
      "Production_lag_15    0\n",
      "Production_lag_16    0\n",
      "Production_lag_17    0\n",
      "Production_lag_18    0\n",
      "Production_lag_19    0\n",
      "Production_lag_20    0\n",
      "Production_lag_21    0\n",
      "Production_lag_22    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfx1.isnull().sum())\n",
    "#dfx1.fillna(method='ffill', inplace=True)\n",
    "dfx1.ffill(inplace=True)\n",
    "print(dfx1.isnull().sum())\n",
    "#dfx1.fillna(method='bfill', inplace=True)\n",
    "dfx1.bfill(inplace=True)\n",
    "print(dfx1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   Year               326999 non-null  datetime64[ns]\n",
      " 1   Area               326999 non-null  float64       \n",
      " 2   Production         326999 non-null  float64       \n",
      " 3   Yield              326999 non-null  float64       \n",
      " 4   Unique_ID          326999 non-null  int32         \n",
      " 5   Production_lag_1   326999 non-null  float64       \n",
      " 6   Production_lag_2   326999 non-null  float64       \n",
      " 7   Production_lag_3   326999 non-null  float64       \n",
      " 8   Production_lag_4   326999 non-null  float64       \n",
      " 9   Production_lag_5   326999 non-null  float64       \n",
      " 10  Production_lag_6   326999 non-null  float64       \n",
      " 11  Production_lag_7   326999 non-null  float64       \n",
      " 12  Production_lag_8   326999 non-null  float64       \n",
      " 13  Production_lag_9   326999 non-null  float64       \n",
      " 14  Production_lag_10  326999 non-null  float64       \n",
      " 15  Production_lag_11  326999 non-null  float64       \n",
      " 16  Production_lag_12  326999 non-null  float64       \n",
      " 17  Production_lag_13  326999 non-null  float64       \n",
      " 18  Production_lag_14  326999 non-null  float64       \n",
      " 19  Production_lag_15  326999 non-null  float64       \n",
      " 20  Production_lag_16  326999 non-null  float64       \n",
      " 21  Production_lag_17  326999 non-null  float64       \n",
      " 22  Production_lag_18  326999 non-null  float64       \n",
      " 23  Production_lag_19  326999 non-null  float64       \n",
      " 24  Production_lag_20  326999 non-null  float64       \n",
      " 25  Production_lag_21  326999 non-null  float64       \n",
      " 26  Production_lag_22  326999 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(25), int32(1)\n",
      "memory usage: 68.6 MB\n"
     ]
    }
   ],
   "source": [
    "dfx1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 326999 entries, 0 to 345374\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Year               326999 non-null  float64\n",
      " 1   Area               326999 non-null  float64\n",
      " 2   Production         326999 non-null  float64\n",
      " 3   Yield              326999 non-null  float64\n",
      " 4   Unique_ID          326999 non-null  int32  \n",
      " 5   Production_lag_1   326999 non-null  float64\n",
      " 6   Production_lag_2   326999 non-null  float64\n",
      " 7   Production_lag_3   326999 non-null  float64\n",
      " 8   Production_lag_4   326999 non-null  float64\n",
      " 9   Production_lag_5   326999 non-null  float64\n",
      " 10  Production_lag_6   326999 non-null  float64\n",
      " 11  Production_lag_7   326999 non-null  float64\n",
      " 12  Production_lag_8   326999 non-null  float64\n",
      " 13  Production_lag_9   326999 non-null  float64\n",
      " 14  Production_lag_10  326999 non-null  float64\n",
      " 15  Production_lag_11  326999 non-null  float64\n",
      " 16  Production_lag_12  326999 non-null  float64\n",
      " 17  Production_lag_13  326999 non-null  float64\n",
      " 18  Production_lag_14  326999 non-null  float64\n",
      " 19  Production_lag_15  326999 non-null  float64\n",
      " 20  Production_lag_16  326999 non-null  float64\n",
      " 21  Production_lag_17  326999 non-null  float64\n",
      " 22  Production_lag_18  326999 non-null  float64\n",
      " 23  Production_lag_19  326999 non-null  float64\n",
      " 24  Production_lag_20  326999 non-null  float64\n",
      " 25  Production_lag_21  326999 non-null  float64\n",
      " 26  Production_lag_22  326999 non-null  float64\n",
      "dtypes: float64(26), int32(1)\n",
      "memory usage: 68.6 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df = dfx1\n",
    "df['Year'] = df['Year'].dt.year.astype(float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326999, 27)\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "n_features = df.shape[-1]\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 326999 entries, 0 to 326998\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Year               326999 non-null  float64\n",
      " 1   Area               326999 non-null  float64\n",
      " 2   Yield              326999 non-null  float64\n",
      " 3   Unique_ID          326999 non-null  float64\n",
      " 4   Production_lag_1   326999 non-null  float64\n",
      " 5   Production_lag_2   326999 non-null  float64\n",
      " 6   Production_lag_3   326999 non-null  float64\n",
      " 7   Production_lag_4   326999 non-null  float64\n",
      " 8   Production_lag_5   326999 non-null  float64\n",
      " 9   Production_lag_6   326999 non-null  float64\n",
      " 10  Production_lag_7   326999 non-null  float64\n",
      " 11  Production_lag_8   326999 non-null  float64\n",
      " 12  Production_lag_9   326999 non-null  float64\n",
      " 13  Production_lag_10  326999 non-null  float64\n",
      " 14  Production_lag_11  326999 non-null  float64\n",
      " 15  Production_lag_12  326999 non-null  float64\n",
      " 16  Production_lag_13  326999 non-null  float64\n",
      " 17  Production_lag_14  326999 non-null  float64\n",
      " 18  Production_lag_15  326999 non-null  float64\n",
      " 19  Production_lag_16  326999 non-null  float64\n",
      " 20  Production_lag_17  326999 non-null  float64\n",
      " 21  Production_lag_18  326999 non-null  float64\n",
      " 22  Production_lag_19  326999 non-null  float64\n",
      " 23  Production_lag_20  326999 non-null  float64\n",
      " 24  Production_lag_21  326999 non-null  float64\n",
      " 25  Production_lag_22  326999 non-null  float64\n",
      " 26  Production         326999 non-null  float64\n",
      "dtypes: float64(27)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "features = df.drop(columns=['Production']).values\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=df.columns.drop('Production'))\n",
    "df_scaled['Production'] = df['Production'].values\n",
    "df_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, target_column, sequence_length):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data.iloc[idx:idx + self.sequence_length].drop(columns=[self.target_column]).values\n",
    "        y = self.data.iloc[idx + self.sequence_length][self.target_column]\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 22\n",
    "dataset = TimeSeriesDataset(df_scaled, 'Production', sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = len(df_scaled.columns) - 1  # Number of features\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "model = RNNModel(input_size, hidden_size, output_size)\n",
    "model = LSTMModel(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 152847879754.6546\n",
      "Epoch 2/100, Loss: 152835005287.9501\n",
      "Epoch 3/100, Loss: 152823037899.1194\n",
      "Epoch 4/100, Loss: 152814703095.1487\n",
      "Epoch 5/100, Loss: 152799482403.8258\n",
      "Epoch 6/100, Loss: 153114149030.1830\n",
      "Epoch 7/100, Loss: 152772549829.6366\n",
      "Epoch 8/100, Loss: 153068516698.4178\n",
      "Epoch 9/100, Loss: 152748121603.9530\n",
      "Epoch 10/100, Loss: 152736035879.9491\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      9\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sequences, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     11\u001b[0m         sequences, targets \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[27], line 11\u001b[0m, in \u001b[0;36mTimeSeriesDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m:\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequence_length\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     12\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_length][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), torch\u001b[38;5;241m.\u001b[39mtensor(y, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5570\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\generic.py:4785\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4783\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4785\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\generic.py:4866\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4863\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   4865\u001b[0m bm_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m axis_num \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4866\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4869\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4872\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4874\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_mgr, axes\u001b[38;5;241m=\u001b[39mnew_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   4875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slice_take_blocks_ax0\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_slice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_proxy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[0;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mgr_locs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmgr_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shyam\\OneDrive\\Desktop\\DL_prac\\PyTorch_Tut\\.myenv\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "xt = []\n",
    "yt = []\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for sequences, targets in train_loader:\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        targets = targets.view(-1, 1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    xt.append(epoch+1)\n",
    "    yt.append(avg_epoch_loss)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {avg_epoch_loss:.4f}')\n",
    "\n",
    "xt = np.array(xt)\n",
    "yt = np.array(yt)\n",
    "plt.plot(xt,yt)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Avg_Epoch per Epoch\")\n",
    "plt.title(\"Epoch vs Loss Plot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for sequences, targets in test_loader:\n",
    "        sequences, targets = sequences.to(device), targets.to(device)\n",
    "        outputs = model(sequences)\n",
    "        targets = targets.view(-1, 1) \n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
